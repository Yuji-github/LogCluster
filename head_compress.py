import re
from re import Pattern
import time_stamp_compress
from statistics import mode
import numpy as np


def __replace_with_dict2_generic(ar: np.ndarray, dic: dict) -> np.ndarray:
    """replace timestamp with int such as 0

    :param ar: np.ndarray of timestamp
    :param dic: dict of unique timestamps
    :return: np.ndarray of timestamps difference
    """
    # Extract out keys and values
    k = np.array(list(dic.keys()))
    v = np.array(list(dic.values()))

    # Get argsort indices
    sidx = k.argsort()

    ks = k[sidx]
    vs = v[sidx]
    idx = np.searchsorted(ks, ar)

    idx[idx == len(vs)] = 0
    mask = ks[idx] == ar
    return np.where(mask, vs[idx], ar)


def __extract_variable(*args) -> None:
    """extract patten of header and write the results
    :param args: ndarray of timestamp and save path of header
    :return: None
    """
    head = args[0]
    head_path = args[1]
    itr = head[0]
    head = np.delete(head, 0)
    unique = []  # to store unique values from each column with a dict

    # for itr in head:
    temp = {
        val: index for index, val in enumerate(np.unique(head))
    }  # val is key and index is items
    unique.append(
        temp
    )  # {'Jun': 0, 'Jul': 1, 'Aug': 2, 'Sep': 3, 'Oct': 4, 'Nov': 5, 'Dec': 6, 'Jan': 7, 'Feb': 8}

    # compress dict
    for val in unique:  # iterate each column
        # itr is index number, val is dict {'Jun': 0, 'Jul': 1, ...}
        key_list = list(val.keys())  # ['Jun', 'Jul', ...]
        digit = True  # to check the column has digits only

        for checker in key_list:  # check all values are digits
            if not str(checker).lstrip("-").isdigit():  # any negative also digits
                digit = False
                break

        if digit:  # this column contains digits only
            d_array = head.astype("int32")
            common = mode(d_array)  # to calculate (still int32 -> 32 bits = 4 bytes)
            gap = d_array - common  # many zeros will contain due to mode (still int32)
            bit = 32  # for decoding

            """Change the type to int8, int16, otherwise, int32 -> save memory space"""
            if -128 <= gap.min() and gap.max() <= 127:  # 8 bits
                gap = gap.astype("int8")
                bit = 8
            elif -32768 <= gap.min() and gap.max() <= 32768:  # 16 bits
                gap = gap.astype("int16")
                bit = 16

            save = head_path + "H_Decode" + str(itr)
            f = open(save + ".txt", "w")
            f.write(
                str(bit) + " " + str(common)
            )  # store mode value and bit for decoding
            f.close()  # close file

            save = head_path + "H_Encode" + str(itr)
            f = open(save + ".txt", "wb")  # write with 8, 16, or 32 bits
            f.write(gap)  # store mode value and bit for decoding
            f.close()  # close file

        else:  # this column has variables -> dict
            save = (
                head_path + "H_Dict" + str(itr)
            )  # save dict for this column # ['Jun', 'Jul', ...]
            f = open(save + ".txt", "w", encoding="ISO-8859-1", errors="ignore")
            for value in key_list:
                f.write(value + "\n")
            f.close()

            # replace dict key from the original values with dict index
            head = __replace_with_dict2_generic(
                head, temp
            )  # ['Jun', 'Jul', ...] -> [0, 1, ...]

            save_np = head.astype(
                dtype="uint32"
            )  # extract the column into numpy with Uint32 -> 0 to 4,294,967,295 (index starts from 0)
            bit = 32  # to decode

            """Change the type to int8, int16, otherwise, int32 -> save memory space"""
            if save_np.max() <= 255:  # 8 bits
                save_np = save_np.astype("uint8")
                bit = 8
            elif save_np.max() <= 4294967295:  # 16 bits
                save_np = save_np.astype("uint16")
                bit = 16

            save = head_path + "H_Decode" + str(itr)
            f = open(save + ".txt", "w")
            f.write(str(bit))  # store bit for decoding
            f.close()

            save = head_path + "H_Encode" + str(itr)
            f = open(save + ".txt", "wb")  # write with 8, 16, or 32 bits
            f.write(save_np)  # store dict index
            f.close()


def extract_header(
    headers: list, time_regex: Pattern, split_regex: Pattern, head_path: str, num: int
) -> None:
    """extract header  to compress it

    :param headers: list of headers (generated by log loader)
    :param time_regex: time stamp regex pattern
    :param split_regex: split regex pattern
    :param head_path: save path
    :param num: number of laps
    :return: None
    """
    temp = []
    time_stamp = []  # timestamp uses special encoding

    for header in headers:
        val = split_regex.split(
            header.strip()
        )  # ex) split by \s -> ['Jun', '', '9', '06:06:20', ...]for idx, time_s in enumerate(val)

        for idx, time_s in enumerate(val):  # replace timestamp with 't'
            if re.search(time_regex, time_s) is not None:  # True
                time_stamp.append(time_s)
                val[idx] = "t"

        temp.append(val)

    head = np.asarray(temp).T
    index = np.arange(len(head))
    index = index.reshape(len(index), 1)
    head = np.concatenate((index, head), axis=1)

    # multi thread process to make faster
    # with ThreadPoolExecutor(max_workers=1) as exe:
    for val in head:  # calling 2d array
        __extract_variable(val, head_path)

    # if TimeStamp is included
    if len(time_stamp) > 0:
        time_stamp_compress.time_compress(time_stamp, head_path, num)
